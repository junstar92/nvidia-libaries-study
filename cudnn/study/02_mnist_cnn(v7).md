# Table of Contents

- [Table of Contents](#table-of-contents)
- [MNIST Classification using Convolution Neural Network](#mnist-classification-using-convolution-neural-network)
- [Inference 결과](#inference-결과)
- [References](#references)

<br>

# MNIST Classification using Convolution Neural Network

이번 포스팅에서는 간단한 CNN 모델을 통해 MNIST Classification을 구현한다. cuDNN v7의 legacy API를 사용했으며, 데이터 타입은 FP32로 지정했다. 전체 코드는 아래 링크를 통해 확인할 수 있다.

- [mnist_cnn](/cudnn/code/mnist_cnn_v7/)

파일 구성은 다음과 같다.

- [layer.h](/cudnn/code/mnist_cnn_v7/layer.h) : CNN 모델을 구성하는 각 레이어를 정의
- [mnist_cnn.h](/cudnn/code/mnist_cnn_v7/mnist_cnn.h) : CNN 모델 정의
- [utils.h](/cudnn/code/mnist_cnn_v7/utils.h) : 유틸리티 코드 및 차원 구조체 정의
- [main.cpp](/cudnn/code/mnist_cnn_v7/main.cpp) : main 코드

레이어 클래스나 CNN 모델을 정의하는 클래스는 직관적으로 구현되어 있기 때문에 따로 설명은 하지 않는다.

Device 메모리는 입력과 출력에 대한 메모리만 main 함수 내에서 관리하며, 이외의 메모리(파라미터 등)는 CNN 모델 클래스 내부에서 관리한다.

추론 시, 중간 결과를 저장하는 메모리가 필요하다. 모델 클래스 내부에서는 메모리 효율성을 위해, 각 레이어의 입력과 출력에 대한 메모리를 모두 할당하는 것이 아닌, 충분한 크기를 갖는 두 개의 메모리만 할당한다. 그리고, 이 두 메모리를 번갈아 가며 입력과 출력으로 사용하여 중간 과정을 저장한다. 이를 구현한 함수가 `MnistCNN` 클래스의 `forward(const void* src, void* dst)` 멤버 함수이다. 구현은 다음과 같다.

```c++
void forward(const void* src, void* dst) {
    int src_idx = 0, dst_idx = 1;
    int layer_idx = 0, layer_len = m_layers.size();
    m_layers[layer_idx]->forward(m_handle, src, m_dev_mem[src_idx]);
    for (layer_idx = 1; layer_idx < layer_len - 1; layer_idx++) {
        m_layers[layer_idx]->forward(m_handle, m_dev_mem[src_idx], m_dev_mem[dst_idx]);
        std::swap(src_idx, dst_idx);
    }
    m_layers[layer_len - 1]->forward(m_handle, m_dev_mem[src_idx], dst);
}
```

주목할 부분은 for 루프 내부이며, 이전 레이어의 출력으로 사용된 메모리는 다음 레이어의 입력으로 사용된다. 마찬가지로 이전 레이어의 입력은 다음 레이어에서 더 이상 필요하지 않으므로, 다음 레이어의 출력 메모리로 사용된다.

# Inference 결과

[main.cpp](/cudnn/code/mnist_cnn_v7/main.cpp)에서는 0부터 9까지의 digit에 대한 추론을 수행한다.

```c++
for (int i = 0; i < 10; i++) {
    // get input data
    std::string filename = "digits/" + std::to_string(i) + ".bin";
    loadBinary((void*)digit, 28 * 28, filename.c_str());
    show_digit(digit, 28, 28);
    cudaMemcpy(d_input, digit, sizeof(float) * 28 * 28, cudaMemcpyHostToDevice);

    // inference
    CUDA_ERROR_CHECK(cudaEventRecord(start));
    network.forward(d_input, d_output);
    CUDA_ERROR_CHECK(cudaEventRecord(stop));
    CUDA_ERROR_CHECK(cudaEventSynchronize(stop));
    CUDA_ERROR_CHECK(cudaEventElapsedTime(&msec, start, stop));

    // extract output
    cudaMemcpy(output, d_output, sizeof(float) * 10, cudaMemcpyDeviceToHost);
    
    auto iter = std::max_element(output, output + 10);
    int output_digit = std::distance(output, iter);
    std::cout << "Digit: " << output_digit << " (" << get_prob(output, output_digit) << ")\n";
    std::cout << "Elapsed Time: " << msec << " ms\n\n";
}
```

for 루프 내에서는 각 digit 파일(28x28)을 읽고, device memory로 복사한 뒤 추론을 수행한다. 추론 결과는 0부터 9까지에 대한 logit이며, softmax 연산을 추가로 할 필요없이 가장 큰 값의 인덱스만 찾아주면 해당 인덱스가 입력에 대한 digit 결과가 된다. 위 코드에서는 `std::max_element`로 가장 큰 값의 Iterator를 찾고, 첫 번째 원소와의 거리를 `std::distance`로 계산하여 가장 큰 값의 인덱스를 찾는다.

> 결과에 대한 최종 확률을 계산하기 위해서 `get_prob` 함수 내에서 softmax 연산을 수행하고 있고 있다. 결과 digit만 알고 싶다면, softmax 연산은 수행하지 않아도 된다.

주피터 노트북으로 추론한 결과와 동일한 결과를 출력하는 것을 확인했으며, 컴파일하고 바이너리를 실행하면 다음과 같은 출력 결과를 얻을 수 있다.

> 컴파일 커맨드는 다음과 같다.
> 
> `nvcc -o mnist_cnn -lcudnn -I. main.cpp`

```
...
............................
............................
............................
............................
........**..................
......******................
.....********...............
......***..****.............
.....***....****............
.....**......****...........
.....**.......***...........
.....**...*...***...........
......*..*********..........
.........***********........
..........************......
..................*****.....
....................****....
.........**..........***....
.........***..........***...
..........**..........***...
..........****......*****...
...........*************....
.............*********......
................*...........
............................
............................
............................
............................
Digit: 3 (0.911076)
Elapsed Time: 0.064512 ms

............................
............................
............................
............................
............................
...........*................
...........*.......**.......
..........**........*.......
..........**........*.......
.........**........**.......
........**.........**.......
........**........***.......
.......**.........**........
.......**........***........
.......**........***........
.......**........**.........
.......***....*****.........
........***********.........
................***.........
.................**.........
................***.........
.................**.........
................***.........
................**..........
................*...........
............................
............................
............................
Digit: 4 (1)
Elapsed Time: 0.064512 ms
...
```

RTX3080 PC에서는 하나의 digit을 추론하는데, 약, 0.06 ~ 0.07 ms의 시간이 걸리는 것으로 측정되었다.

<br>

# References

- [NVIDIA cuDNN Documentation: API References](https://docs.nvidia.com/deeplearning/cudnn/api/index.html)
# Table of Contents

- [Warp Level Matrix Multiply-Accumulate Instructions](#warp-level-matrix-multiply-accumulate-instructions)
  - [Matrix Shape](#matrix-shape)
  - [Matrix Data Type](#matrix-data-types)
- [MMA Operation (m16n8k16)](#mma-operation-m16n8k16)
- [Examples](#examples)
  - [with ldmatrx](#with-ldmatrix)
- [References](#references)

# Warp Level Matrix Multiply-Accumulate Instructions

행렬 곱셈은 아래의 형태로 구성된다.
```
D = A * B + C
```

PTX는 matrix multiply-and-accumulate 연산을 수행하는 두 가지 방법을 제공하는데, 하나는 `wmma` 명령어이며 다른 하나는 `mma` 명령어이다. `wmma`와 `mma`는 모두 행렬 연산을 수행하는 명령어라는 점에서 동일하지만, 곱셈의 각 요소를 로드하는 방법에서 차이가 있다. `wmma` 명령어는 `wmma.load`와 `wmma.store` 명령어를 통해 행렬을 로드하고, 그 결과를 다시 쓰게 된다. 반면, `mma`는 명시적으로 각 스레드에 행렬 요소들을 적절히 분배해주어야 한다.

## Matrix Shape

이들 명령어는 제한된 크기의 행렬 곱셈을 지원한다. 예를 들어, fp16 타입에 대한 `mma` 연산은 `8x8x4`, `16x8x8`, `16x8x16` 크기를 지원하며, 명령어에서는 `m8n8k4`, `m16n8k8`, `m16n8k16`으로 나타낸다. [link](https://docs.nvidia.com/cuda/parallel-thread-execution/index.html#warp-level-matrix-shape)에서 지원하는 크기에 대해 확인할 수 있다.

## Matrix Data Types

지원하는 데이터 타입은 다음과 같다.

|Data Type| Multiplicands (A or B) | Accumulators (C or D)|
|---|---|---|
|Integer|`.u8`, `.s8`|`.s32`|
|Floating Point|`.f16`|`.f16`,`.f32`|
|Alternate Floating Point|`.bf16`|`.f32`|
|Alternate Floating Point|`.tf32`|`.f32`|
|Alternate Floating Point|`.e4m3`, `.e5m2`|`.f32`|
|Floating Point|`.f64`|`.f64`|
|Sub-byte Integer|both `.u4` or both `.s4`|`.s32`|
|Single-bit Integer|`.b1`|`.s32`|

# MMA operation (m16n8k16)

MMA 명령어 중 FP16 연산에 사용될 수 있는 `mma.m16n8k16` 명령어를 어떻게 사용할 수 있는지 살펴보자.

`mma.m16n8k16` 명령어는 하나의 워프가 16x8x16 크기에 대한 MMA 연산을 수행하게 된다. 워프 내 각 스레드에 분배되는 행렬 요소는 다음과 같다.

먼저 행렬 A에 해당하는 레이아웃이다.

<img src="https://docs.nvidia.com/cuda/parallel-thread-execution/_images/mma-16816-A-f16.png" width=500px style="display: block; margin: 0 auto; background-color: white"/>

4개의 8x8 행렬로 그룹화되어 각 8x8 행렬 내에서는 동일한 위치의 요소들이 각 스레드에 분배된다. 따라서 사용자는 각 스레드에 분배되어야 하는 요소들을 명시적으로 레지스터에 분배한 뒤, 해당 레지스터의 주소를 `mma` 명령어로 전달하게 된다. 각 스레드에는 8개의 요소가 분배되어 로드된다.

위 레이아웃 기준으로 각 스레드에 분배되어야 하는 요소들의 행/열 위치는 아래와 같이 계산할 수 있다. 
```
groupID           = %laneid >> 2
threadID_in_group = %laneid % 4

row =   groupID            for ai where  0 <= i < 2 || 4 <= i < 6
        groupID + 8        Otherwise

col =   (threadID_in_group * 2) + (i & 0x1)          for ai where i <  4
        (threadID_in_group * 2) + (i & 0x1) + 8      for ai where i >= 4
```

행렬 B에 해당하는 레이아웃은 다음과 같다.

<img src="https://docs.nvidia.com/cuda/parallel-thread-execution/_images/mma-16816-B-f16.png" width=500px style="display: block; margin: 0 auto; background-color: white"/>

행렬 A의 크기는 16x16인 반면, 행렬 B의 크기는 8x16이므로 8x8 크기의 그룹이 총 2개이다. 결과적으로 각 스레드에는 4개의 행렬 요소가 분배되어 로드된다.

다음과 같이 대응하는 행/열 위치를 계산할 수 있다.
```
groupID           = %laneid >> 2
threadID_in_group = %laneid % 4

row =  (threadID_in_group * 2) + (i & 0x1)           for bi where i <  2
       (threadID_in_group * 2) + (i & 0x1) + 8       for bi where i >= 2

col = groupID
```

행렬 C, 즉, accumulator에 해당하는 레이아웃은 다음과 같다.

<img src="https://docs.nvidia.com/cuda/parallel-thread-execution/_images/mma-16816-C-f16.png" width=500px style="display: block; margin: 0 auto; background-color: white"/>

크기가 16x8이므로 행렬 B와 마찬가지로 8x8 크기의 그룹이 2개이며 각 스레드에는 4개의 행렬 요소가 분배된다.

대응하는 행/열 위치는 아래와 같이 계산할 수 있다.
```
groupID           = %laneid >> 2
threadID_in_group = %laneid % 4

row =   groupID                               for ci where i <  2
        groupID + 8                           for ci where i >= 2

col =  (threadID_in_group * 2) + (i & 0x1)    for ci where i = {0,..,3}
```

이렇게 행렬 요소를 분배한 뒤에는 아래와 같은 PTX 명령어를 통해 연산을 수행할 수 있다.
```
mma.sync.aligned.m16n8k16.row.col.dtype.f16.f16.ctype d, a, b, c;

.ctype   = {.f16, .f32};
.dtype   = {.f16, .f32};
```

FP16 타입에 대한 `mma.m16n8k16` 연산에서는 A 행렬은 row-major 레이아웃, B 행렬은 column-major인 경우에만 지원된다. Accumulator 타입은 FP16과 FP32를 지원하는데, 사용할 데이터 타입에 따라서 명령어에 전달되는 메모리 주소의 수가 달라지므로 유의해야 한다. 참고로 FP32를 사용한다면 32비트 레지스터 4개의 주소를 전달하게 되고, FP16을 사용하면 32비트 레지스터 2개의 주소를 전달하게 된다.

# Examples

간단하게 16x8x16 크기의 행렬 곱셈을 수행하는 코드를 작성해보자. 전체 코드는 [link](/cuda/code/ptx_mma/test_mma_m16n8k16_fp16.cu)에서 확인할 수 있다.

전체 커널 코드는 다음과 같다.
```c++
__global__
void mma_m16n8k16_fp16_kernel(half const* A, half const* B, half* C, int const M, int const N, int const K)
{
    int tid = threadIdx.x;
    int lane_id = tid % 32;
    int group_id = lane_id >> 2;
    int tid_in_group = lane_id % 4;

    half a_frag[8], b_frag[4];
    float c_frag[4]{};

    #pragma unroll
    for (int i = 0; i < 4; i++) {
        auto const* tmp_A = A + (i % 2) * (M / 2) * K + (i / 2) * (K / 2) + group_id * K + tid_in_group * 2;
        auto* tmp_a_frag = a_frag + i * 2;
        *reinterpret_cast<float*>(tmp_a_frag) = *reinterpret_cast<float const*>(tmp_A);
    }
    #pragma unroll
    for (int i = 0; i < 2; i++) {
        auto const* tmp_B = B + (i % 2) * (K / 2) + group_id * K + tid_in_group * 2;
        auto* tmp_b_frag = b_frag + i * 2;
        *reinterpret_cast<float*>(tmp_b_frag) = *reinterpret_cast<float const*>(tmp_B);
    }

    mma_m16n8k16_fp16(c_frag, a_frag, b_frag);

    #pragma unroll
    for (int i = 0; i < 2; i++) {
        auto* tmp_C = C + (i % 2) * (M / 2) * N + group_id * N + tid_in_group * 2;
        auto* tmp_c_frag = c_frag + i * 2;
        half2 val = __float22half2_rn(*reinterpret_cast<float2*>(tmp_c_frag));
        *reinterpret_cast<float*>(tmp_C) = *reinterpret_cast<float*>(&val);
    }
}
```

코드는 생각보다 간결하다. 먼저 각 행렬 요소의 값을 각 스레드의 레지스터로 로드하는 부분부터 살펴보자.

먼저 위에서 살펴본 레이아웃처럼 요소를 분배하기 위해 필요한 값들을 정의하고, 그 값들을 저장할 fragment 레지스터 배열을 준비한다.
```c++
int tid = threadIdx.x;
int lane_id = tid % 32;
int group_id = lane_id >> 2;
int tid_in_group = lane_id % 4;

half a_frag[8], b_frag[4];
float c_frag[4]{};
```

다음은 device memory로부터 레지스터로 각 스레드에 분배되어야 하는 요소 값들을 로드한다.
```c++
#pragma unroll
for (int i = 0; i < 4; i++) {
    auto const* tmp_A = A + (i % 2) * (M / 2) * K + (i / 2) * (K / 2) + group_id * K + tid_in_group * 2;
    auto* tmp_a_frag = a_frag + i * 2;
    *reinterpret_cast<float*>(tmp_a_frag) = *reinterpret_cast<float const*>(tmp_A);
}
#pragma unroll
for (int i = 0; i < 2; i++) {
    auto const* tmp_B = B + (i % 2) * (K / 2) + group_id * K + tid_in_group * 2;
    auto* tmp_b_frag = b_frag + i * 2;
    *reinterpret_cast<float*>(tmp_b_frag) = *reinterpret_cast<float const*>(tmp_B);
}
```

행렬 A와 B의 레이아웃을 살펴보면, 전체 행렬은 8x8 크기의 작은 그룹으로 나뉘며 각 스레드에 분배되는 요소의 위치는 각 그룹에서 동일하다. 따라서, 각 그룹별로 루프를 돌면서 같은 위치에 요소들을 레지스터로 로드하도록 구현하였다. 행렬 A는 4개의 서브 행렬로 나뉘고, 행렬 B는 2개의 서브 행렬로 나뉘므로 각 루프의 횟수는 4번, 2번이다. 하나의 그룹에서 2개의 FP16 요소를 로드하므로 FP32 타입으로 묶어서 한 번에 로드한다. FP16 타입으로 각각 로드해도 컴파일러에 의해서 최적화가 되는지 확인해보진 않았다.

다음으로는 `mma` 명령어를 수행해준다. 호출하는 함수의 구현은 다음과 같다.
```c++
__device__
void mma_m16n8k16_fp16(
    float* c,
    half const* a, half const* b
)
{
    uint32_t const *A = reinterpret_cast<uint32_t const*>(a);
    uint32_t const *B = reinterpret_cast<uint32_t const*>(b);

    asm volatile(
        "mma.sync.aligned.m16n8k16.row.col.f32.f16.f16.f32 "
        "{%0, %1, %2, %3},"
        "{%4, %5, %6, %7},"
        "{%8, %9},"
        "{%10, %11, %12, %13};\n"
        : "=f"(c[0]), "=f"(c[1]), "=f"(c[2]), "=f"(c[3])
        : "r"(A[0]), "r"(A[1]), "r"(A[2]), "r"(A[3])
          "r"(B[0]), "r"(B[1]),
          "f"(c[0]), "f"(c[1]), "f"(c[2]), "f"(c[3])
    );
}
```

각 스레드의 fragment로 계산된 결과는 아래와 같이 다시 global memory로 쓰게 된다.
```c++
#pragma unroll
for (int i = 0; i < 2; i++) {
    auto* tmp_C = C + (i % 2) * (M / 2) * N + group_id * N + tid_in_group * 2;
    auto* tmp_c_frag = c_frag + i * 2;
    half2 val = __float22half2_rn(*reinterpret_cast<float2*>(tmp_c_frag));
    *reinterpret_cast<float*>(tmp_C) = *reinterpret_cast<float*>(&val);
}
```

행렬 A와 B의 요소를 레지스터로 로드하는 방식과 동일하다. 각 그룹 내에서 대응하는 위치는 동일하므로 그룹별로 루프를 돌면서 해당하는 위치의 레지스터 값을 global memory로 쓴다. 결과 행렬의 타입을 FP16으로 지정했기 때문에 값을 쓰기 전에 별도의 float to half 변환을 수행해주게 된다.

전체 코드를 컴파일하고 실행해보면 다음과 같이 정상적으로 계산된 결과를 얻을 수 있다.
```
Ref Results:
 0.1240  0.3162  0.5078  0.7002  0.8926  1.0840  1.2764  1.4688 
 0.3162  0.9175  1.5195  2.1191  2.7207  3.3242  3.9258  4.5273 
 0.5078  1.5195  2.5312  3.5410  4.5469  5.5625  6.5781  7.5859 
 0.7002  2.1191  3.5410  4.9609  6.3828  7.8008  9.2266 10.6484 
 0.8926  2.7207  4.5469  6.3828  8.2109 10.0469 11.8672 13.7031 
 1.0840  3.3242  5.5625  7.8008 10.0469 12.2891 14.5234 16.7656 
 1.2764  3.9258  6.5781  9.2266 11.8672 14.5234 17.1719 19.8281 
 1.4688  4.5273  7.5859 10.6484 13.7031 16.7656 19.8281 22.8594 
 1.6611  5.1250  8.5938 12.0703 15.5312 19.0000 22.4688 25.9219 
 1.8525  5.7305  9.6172 13.4844 17.3594 21.2344 25.1250 28.9844 
 2.0430  6.3281 10.6172 14.9062 19.2031 23.4844 27.7656 32.0625 
 2.2363  6.9336 11.6328 16.3281 21.0312 25.7188 30.4219 35.1250 
 2.4297  7.5273 12.6562 17.7500 22.8594 27.9531 33.0625 38.2188 
 2.6191  8.1406 13.6484 19.1719 24.6875 30.2344 35.7188 41.2500 
 2.8145  8.7344 14.6641 20.5625 26.5312 32.4375 38.3750 44.3125 
 3.0039  9.3359 15.6719 22.0312 28.3594 34.7188 41.0312 47.3438 

Device Results:
 0.1240  0.3159  0.5078  0.7002  0.8921  1.0840  1.2764  1.4678 
 0.3159  0.9175  1.5195  2.1211  2.7227  3.3242  3.9258  4.5273 
 0.5078  1.5195  2.5293  3.5410  4.5547  5.5625  6.5742  7.5859 
 0.7002  2.1211  3.5410  4.9609  6.3828  7.8047  9.2266 10.6484 
 0.8921  2.7227  4.5547  6.3828  8.2109 10.0469 11.8750 13.7031 
 1.0840  3.3242  5.5625  7.8047 10.0469 12.2812 14.5234 16.7656 
 1.2764  3.9258  6.5742  9.2266 11.8750 14.5234 17.1719 19.8281 
 1.4678  4.5273  7.5859 10.6484 13.7031 16.7656 19.8281 22.8750 
 1.6602  5.1289  8.5938 12.0625 15.5391 19.0000 22.4688 25.9375 
 1.8516  5.7305  9.6094 13.4844 17.3594 21.2500 25.1250 29.0000 
 2.0449  6.3320 10.6172 14.9062 19.2031 23.4844 27.7656 32.0625 
 2.2363  6.9336 11.6328 16.3281 21.0312 25.7188 30.4219 35.1250 
 2.4277  7.5352 12.6406 17.7500 22.8594 27.9688 33.0625 38.1875 
 2.6211  8.1406 13.6562 19.1719 24.6875 30.2031 35.7188 41.2500 
 2.8125  8.7422 14.6641 20.5938 26.5156 32.4375 38.3750 44.2812 
 3.0039  9.3438 15.6719 22.0156 28.3438 34.6875 41.0312 47.3438
```

## with ldmatrix

위에서 각 행렬은 8x8 크기의 그룹으로 나누어져서 각 요소들이 스레드로 로드된다고 언급했다. 또한, 각 스레드에서 레지스터 배열의 위치가 `ldmatrix` 명령어를 사용하면 로드되는 위치와 동일하다는 것을 확인할 수 있다. 따라서, `ldmatrix` 사용하여 레지스터로 행렬 요소의 값을 적절한 위치로 분배할 수 있다.

그 구현은 다음과 같다. 아래 코드에서는 `.x4`를 사용하여 행렬 A의 요소를 shared memory로부터 레지스터로 로드하고, `.x2`를 사용하여 행렬 B의 요소를 레지스터로 로드한다. `stmarix`는 SM 90부터 사용이 가능하여 따로 적용하지 않았다.

```c++
__device__
void ldm4(half* dst, half const* src)
{
    uint32_t* reg_ptr = reinterpret_cast<uint32_t*>(dst);
    uint32_t shmem_ptr = __cvta_generic_to_shared(src);

    asm volatile(
        "ldmatrix.sync.aligned.m8n8.x4.shared.b16 {%0, %1, %2, %3}, [%4];"
        : "=r"(reg_ptr[0]), "=r"(reg_ptr[1]), "=r"(reg_ptr[2]), "=r"(reg_ptr[3])
        : "r"(shmem_ptr)
    );
}

__device__
void ldm2(half* dst, half const* src)
{
    uint32_t* reg_ptr = reinterpret_cast<uint32_t*>(dst);
    uint32_t shmem_ptr = __cvta_generic_to_shared(src);

    asm volatile(
        "ldmatrix.sync.aligned.m8n8.x2.shared.b16 {%0, %1}, [%2];"
        : "=r"(reg_ptr[0]), "=r"(reg_ptr[1])
        : "r"(shmem_ptr)
    );
}

__global__
void mma_m16n8k16_fp16_kernel2(half const* A, half const* B, half* C, int const M, int const N, int const K)
{
    int tid = threadIdx.x;
    int lane_id = tid % 32;
    int group_id = lane_id >> 2;
    int tid_in_group = lane_id % 4;

    __shared__ half a_shmem[16*16], b_shmem[8*16];
    *reinterpret_cast<float4*>(a_shmem + 8 * tid) = *reinterpret_cast<float4 const*>(A + 8 * tid);
    *reinterpret_cast<float2*>(b_shmem + 4 * tid) = *reinterpret_cast<float2 const*>(B + 4 * tid);

    half a_frag[8], b_frag[4], c_frag[4]{};

    half* a_shmem_row = a_shmem + (lane_id % 16) * K + ((lane_id >> 3) / 2) * (K / 2);
    half* b_shmem_row = b_shmem + (lane_id % 8) * K + ((lane_id >> 3) % 2) * (K / 2);

    ldm4(a_frag, a_shmem_row);
    ldm2(b_frag, b_shmem_row);

    mma_m16n8k16_fp16(c_frag, a_frag, b_frag);

    #pragma unroll
    for (int i = 0; i < 2; i++) {
        auto* tmp_C = C + (i % 2) * (M / 2) * N + group_id * N + tid_in_group * 2;
        auto* tmp_c_frag = c_frag + i * 2;
        *reinterpret_cast<float*>(tmp_C) = *reinterpret_cast<float*>(tmp_c_frag);
    }
}
```

# References

- [Matrix Fragments for mma.m16k8n16 with floating point type](https://docs.nvidia.com/cuda/parallel-thread-execution/index.html#matrix-fragments-for-mma-m16n8k16-with-floating-point-type)
- [Warp-level matrix load instruction (ldmatrix)](/cuda/study/28_ldmatrix.md)